# Evaluation & Prioritization Frameworks

Comprehensive methods for converging from many ideas to actionable priorities.

## Table of Contents

- [The Convergence Process](#the-convergence-process)
- [Quick Filtering Methods](#quick-filtering-methods)
- [Impact vs Effort Matrix](#impact-vs-effort-matrix)
- [Weighted Scoring](#weighted-scoring)
- [Priority Matrices](#priority-matrices)
- [Feasibility Analysis](#feasibility-analysis)
- [Risk Assessment](#risk-assessment)
- [Group Decision Methods](#group-decision-methods)

---

## The Convergence Process

### Diverge-Converge Cycle

**Divergent Phase** (Generate):
- Goal: Maximum quantity
- Mindset: Open, expansive, non-judgmental
- Output: Many ideas

**Convergent Phase** (Evaluate):
- Goal: Select best options
- Mindset: Critical, analytical, decisive
- Output: Prioritized shortlist

**Critical Rule**: Complete divergence BEFORE converging. Never mix generation and evaluation.

### Convergence Stages

#### Stage 1: Organize (5 minutes)
- Group similar ideas
- Eliminate duplicates
- Clarify unclear items
- Count what you have

#### Stage 2: Initial Filter (5 minutes)
- Remove obviously unviable ideas
- Flag clear winners
- Identify interesting but unclear items
- Reduce by 30-50%

#### Stage 3: Deep Evaluation (10-15 minutes)
- Apply chosen framework
- Score remaining ideas
- Compare systematically
- Discuss trade-offs

#### Stage 4: Selection (5 minutes)
- Choose top 3-5 ideas
- Define next steps for each
- Park remaining ideas for later
- Document decision rationale

---

## Quick Filtering Methods

### Gut Check

**Best for**: Initial filtering, time constraints

**Process**:
1. Read through all ideas quickly
2. Mark instinctive reactions: ★ = love, ○ = maybe, ✗ = no
3. Count stars
4. Discuss ideas with most stars
5. Select top 3-5

**Pros**: Fast, intuitive, easy
**Cons**: May miss analytical insights

**Time**: 5-10 minutes

---

### Dot Voting

**Best for**: Group decisions, democratic process

**Process**:
1. Give each person 3-5 "dots" (votes)
2. Everyone places dots on their favorite ideas
3. Can use multiple dots on one idea
4. Tally votes
5. Discuss top vote-getters

**Variations**:
- Red dots = concerns, Green dots = support
- Different colored dots for different criteria
- Weighted dots (some worth more)

**Pros**: Inclusive, visual, fun
**Cons**: Groupthink risk

**Time**: 5-10 minutes

---

### Must/Should/Could/Won't (MoSCoW)

**Best for**: Feature prioritization, requirement analysis

**Categories**:
- **Must**: Non-negotiable, critical
- **Should**: Important but not vital
- **Could**: Nice to have
- **Won't**: Not now (parking lot)

**Process**:
1. Place each idea in one category
2. Start by identifying "Must" items
3. Then "Won't" items
4. Remaining go to Should/Could
5. Prioritize within categories

**Pros**: Clear categories, good for requirements
**Cons**: Can become political

**Time**: 10 minutes

---

### Three Stars

**Best for**: Quick individual prioritization

**Process**:
1. Each person selects their top 3 ideas (three stars)
2. Share and discuss selections
3. Look for consensus
4. Explore interesting disagreements
5. Decide based on patterns

**Pros**: Simple, forces hard choices
**Cons**: May miss valuable ideas outside top 3

**Time**: 5 minutes

---

### COCD Box (Collaborative, Creative, Defensive)

**Best for**: Balancing innovation with practicality

**Four Quadrants**:
1. **Easy & New**: Quick wins, experimental
2. **Hard & New**: Long-term innovations
3. **Easy & Familiar**: Safe improvements
4. **Hard & Familiar**: Required maintenance

**Process**:
1. Draw 2x2 matrix (Easy/Hard vs New/Familiar)
2. Place each idea in appropriate quadrant
3. Balance portfolio across quadrants
4. Prioritize based on strategy

**Pros**: Strategic, balanced view
**Cons**: Subjective categorization

**Time**: 15 minutes

---

## Impact vs Effort Matrix

### Overview

The most popular prioritization method. Plot ideas on 2x2 matrix:
- X-axis: Effort (Low → High)
- Y-axis: Impact (Low → High)

### Four Quadrants

**High Impact, Low Effort** (DO FIRST):
- Quick wins
- Highest priority
- Implement immediately
- "Low-hanging fruit"

**High Impact, High Effort** (PLAN FOR):
- Major initiatives
- Require resources
- Strategic importance
- Long-term projects

**Low Impact, Low Effort** (MAYBE):
- Fill-in tasks
- When you have time
- Low priority
- Quick improvements

**Low Impact, High Effort** (AVOID):
- Time sinks
- Reconsider value
- Don't do
- Parking lot

### Step-by-Step Process

#### 1. Define Scales (3 minutes)

**Impact Scale**: What does high impact mean?
- Revenue generated?
- Customer satisfaction?
- Problem solved?
- Strategic value?

Define 1-10 or Low/Medium/High

**Effort Scale**: What does high effort mean?
- Time required?
- Resources needed?
- Complexity?
- Dependencies?

Define consistently

#### 2. Score Ideas (10 minutes)

**For each idea**:
- Estimate impact score
- Estimate effort score
- Plot on matrix
- Can use 1-10 or Low/Med/High

**Tips**:
- Score relative to each other
- Use same definition for all
- Quick estimates are fine
- Document assumptions

#### 3. Plot Matrix (2 minutes)

```
Impact
  ↑
  10│    PLAN FOR  │  DO FIRST
    │              │
  5 │    AVOID     │   MAYBE
    │              │
  0 └──────────────┴──────────→ Effort
    0              5           10
```

Place each idea in appropriate quadrant

#### 4. Discuss & Decide (5 minutes)

**Focus on**:
- All "Do First" ideas
- Selected "Plan For" ideas
- Question "Avoid" ideas

**Make decisions**:
- Which to implement?
- What's the sequence?
- Who owns what?

### Example

**Ideas for improving customer onboarding**:

Plotted:
```
Impact
  ↑
  H │  Personalized    │  Interactive
    │  guidance(5,3)   │  tutorial(8,2)
    │                  │
  M │  New colors(3,5) │  Welcome email(5,4)
    │                  │  Tooltips(6,4)
  L │  Longer video(2,6)│ Quick tips(2,2)
    │                  │
    └──────────────────┴──────────→ Effort
      L        M        H
```

**Decision**:
1. **Do First**: Interactive tutorial (H impact, L effort)
2. **Plan For**: Personalized guidance, Welcome email, Tooltips
3. **Maybe**: Quick tips
4. **Avoid**: New colors, Longer video

### Facilitation Tips

**Use visual**: Draw actual matrix if possible

**Discuss outliers**: Challenge extreme scores

**Relative scoring**: Compare to each other, not absolute

**Time-box scoring**: Don't overthink

**Update as learn**: Scores can change with more info

**Consider dependencies**: Some efforts unlock others

---

## Weighted Scoring

### Overview

Score ideas against multiple criteria with different weights based on importance.

### When to Use

- Multiple important criteria
- Need objective comparison
- Complex decisions
- Stakeholder alignment needed

### Step-by-Step Process

#### 1. Define Criteria (5 minutes)

**Choose 3-7 criteria**:
- What matters for this decision?
- What defines success?
- What constraints exist?

Examples:
- Impact on users
- Technical feasibility
- Cost
- Time to implement
- Strategic alignment
- Risk level
- Team capacity

#### 2. Weight Criteria (3 minutes)

**Assign importance weight** (percentage totaling 100%):
- What's most important?
- What's non-negotiable?
- What's nice-to-have?

Example:
```
User Impact:        35%
Feasibility:        25%
Cost:              20%
Time:              15%
Strategic Fit:       5%
─────────────────────
Total:             100%
```

#### 3. Score Each Idea (10-15 minutes)

**Rate each idea on each criterion** (1-10 scale):

```
Idea A: New Feature X

User Impact:     8/10
Feasibility:     6/10
Cost:           7/10 (lower is better, flip scale)
Time:           8/10 (faster is better)
Strategic Fit:   9/10
```

#### 4. Calculate Weighted Scores (5 minutes)

**For each idea**:
```
Weighted Score = (Criterion₁ × Weight₁) + (Criterion₂ × Weight₂) + ...
```

**Example for Idea A**:
```
(8 × 0.35) + (6 × 0.25) + (7 × 0.20) + (8 × 0.15) + (9 × 0.05)
= 2.8 + 1.5 + 1.4 + 1.2 + 0.45
= 7.35 / 10
```

#### 5. Compare and Decide (5 minutes)

**Rank by weighted score**:
- Highest scores = priorities
- Look at individual criteria too
- Discuss close scores
- Make final decision

### Full Example

**Decision**: Choose marketing channel for launch

**Criteria & Weights**:
```
Reach:              30%
Cost:               25%
Measurability:      20%
Control:            15%
Speed:              10%
```

**Scoring** (scale 1-10):

| Channel       | Reach | Cost | Measur. | Control | Speed | Weighted |
|---------------|-------|------|---------|---------|-------|----------|
| Social Ads    | 8     | 6    | 9       | 7       | 9     | **7.45** |
| Content Mktg  | 7     | 9    | 7       | 9       | 4     | 7.35     |
| PR Campaign   | 9     | 5    | 4       | 3       | 6     | 6.35     |
| Email         | 5     | 10   | 10      | 10      | 10    | 7.25     |
| Events        | 6     | 3    | 6       | 8       | 3     | 5.25     |

**Calculations**:
```
Social Ads:
(8×0.30) + (6×0.25) + (9×0.20) + (7×0.15) + (9×0.10) = 7.45

Content Marketing:
(7×0.30) + (9×0.25) + (7×0.20) + (9×0.15) + (4×0.10) = 7.35
```

**Decision**: Social Ads wins, but Content Marketing is close. Consider combining.

### Tips for Weighted Scoring

**Criteria selection**:
- Keep to 3-7 criteria (too many = complex)
- Make criteria independent
- Use clear definitions

**Weighting**:
- Total must equal 100%
- Big differences mean clear priorities
- Similar weights = all important

**Scoring**:
- Use consistent scale (1-10 recommended)
- Define what each score means
- Can use team average
- Document reasoning

**Interpretation**:
- Don't over-rely on numbers
- Use as discussion tool
- Consider sensitivity analysis
- Trust but verify

---

## Priority Matrices

### Eisenhower Matrix (Urgent-Important)

**Four Quadrants**:
```
Important
    ↑
    │ DO FIRST    │ SCHEDULE
    │ (1)         │ (2)
────┼─────────────┼──────────→ Urgent
    │ DELEGATE    │ ELIMINATE
    │ (3)         │ (4)
```

**Quadrant 1** (Urgent & Important):
- Crises and emergencies
- Deadlines
- Do immediately

**Quadrant 2** (Not Urgent but Important):
- Planning and strategy
- Relationship building
- Most valuable long-term
- Schedule time for these

**Quadrant 3** (Urgent but Not Important):
- Interruptions
- Some meetings
- Delegate if possible

**Quadrant 4** (Not Urgent, Not Important):
- Busywork
- Time wasters
- Eliminate

**Best for**: Time management, task prioritization

---

### Value vs Complexity

Similar to Impact/Effort but focuses on:
- Y-axis: Business Value
- X-axis: Implementation Complexity

**Quadrants**:
- High Value, Low Complexity: DO
- High Value, High Complexity: PLAN
- Low Value, Low Complexity: MAYBE
- Low Value, High Complexity: AVOID

**Best for**: Product features, technical decisions

---

### Risk vs Reward

**Axes**:
- Y-axis: Potential Reward
- X-axis: Risk Level

**Quadrants**:
- High Reward, Low Risk: PURSUE
- High Reward, High Risk: CALCULATE (worth the risk?)
- Low Reward, Low Risk: SAFE (but boring)
- Low Reward, High Risk: AVOID

**Best for**: Strategic decisions, investments

---

### Now/Next/Later

**Three horizons**:
- **Now**: Current sprint/month, highest priority
- **Next**: Next sprint/quarter, important but not urgent
- **Later**: Future consideration, parking lot

**Process**:
1. Sort all ideas into three buckets
2. Limit "Now" to what's achievable
3. Define clear criteria for each
4. Review regularly

**Best for**: Roadmap planning, agile prioritization

---

## Feasibility Analysis

### Overview

Assess whether ideas can actually be implemented successfully.

### Feasibility Dimensions

#### Technical Feasibility
- Do we have the technical capability?
- Do required technologies exist?
- Are there technical risks?
- Can we build this?

**Questions**:
- What technical challenges exist?
- Do we have the skills?
- What's the technical risk?

**Rating**: 1 (impossible) to 5 (easy)

#### Economic Feasibility
- Can we afford this?
- What's the ROI?
- What are costs?
- What's the budget?

**Questions**:
- What does this cost?
- What's the return?
- Is this economically viable?

**Rating**: 1 (too expensive) to 5 (great ROI)

#### Operational Feasibility
- Can we operate this?
- Do we have capacity?
- Does it fit our processes?
- Can we maintain it?

**Questions**:
- Can we support this?
- Do we have resources?
- Does this fit our operations?

**Rating**: 1 (operationally problematic) to 5 (easy to operate)

#### Timeline Feasibility
- Can we do this in time?
- What's the deadline?
- Are there time constraints?
- Is timeline realistic?

**Questions**:
- How long will this take?
- When do we need it?
- Is the timeline realistic?

**Rating**: 1 (unrealistic timeline) to 5 (plenty of time)

### Feasibility Scoring

**For each idea, score 1-5 on each dimension**:

```
Idea: Mobile App

Technical:      4/5 (we have the skills)
Economic:       3/5 (expensive but viable)
Operational:    3/5 (will need new processes)
Timeline:       2/5 (tight deadline)
──────────────────
Average:        3.0/5

Overall: FEASIBLE but challenging
```

**Interpretation**:
- Average >4.0: Highly feasible
- Average 3.0-4.0: Feasible with effort
- Average 2.0-3.0: Challenging
- Average <2.0: Not feasible

**Red flags**:
- Any dimension scoring 1
- Multiple dimensions scoring 2
- Significant risks identified

---

## Risk Assessment

### Risk Matrix

**Axes**:
- Y-axis: Impact if risk occurs (Low → High)
- X-axis: Likelihood of occurrence (Low → High)

**Quadrants**:
```
Impact
    ↑
    │ MONITOR    │ MITIGATE
  H │            │
────┼────────────┼──────────→ Likelihood
  L │ IGNORE     │ ACCEPT
    │ L          H
```

**Action for each quadrant**:
- **Low Impact, Low Likelihood**: Ignore/Accept
- **Low Impact, High Likelihood**: Accept/Monitor
- **High Impact, Low Likelihood**: Monitor/Contingency plan
- **High Impact, High Likelihood**: Mitigate/Avoid

### Risk Assessment Process

#### 1. Identify Risks (5 minutes)

**For each idea, ask**:
- What could go wrong?
- What assumptions might be wrong?
- What dependencies exist?
- What external factors matter?

Generate list of potential risks

#### 2. Assess Each Risk (5 minutes)

**Score 1-5**:
- **Likelihood**: How probable? (1=rare, 5=certain)
- **Impact**: How severe? (1=minor, 5=catastrophic)

**Calculate risk score**: Likelihood × Impact

```
Risk: Technical complexity delays launch

Likelihood: 4/5 (likely)
Impact:     4/5 (significant)
Risk Score: 16/25 (HIGH)
```

#### 3. Prioritize Risks (3 minutes)

**Focus on**:
- Risk score >15: High priority
- Risk score 10-15: Medium priority
- Risk score <10: Low priority

#### 4. Plan Mitigation (10 minutes)

**For high-priority risks**:
- How can we reduce likelihood?
- How can we reduce impact?
- What's our contingency plan?
- Who monitors this?

### Example Risk Assessment

**Idea**: Launch new pricing tier

**Risks Identified**:

1. **Existing customers upset**
   - Likelihood: 4/5
   - Impact: 5/5
   - Score: 20 (**CRITICAL**)
   - Mitigation: Grandfather existing customers, clear communication

2. **Technical integration issues**
   - Likelihood: 3/5
   - Impact: 3/5
   - Score: 9 (Medium)
   - Mitigation: Thorough testing, phased rollout

3. **Insufficient demand**
   - Likelihood: 2/5
   - Impact: 4/5
   - Score: 8 (Medium)
   - Mitigation: Market research, pilot program

4. **Competitor response**
   - Likelihood: 4/5
   - Impact: 2/5
   - Score: 8 (Medium)
   - Mitigation: Monitor competitor, be ready to adjust

**Decision**: Proceed with strong focus on customer communication and grandfather clause.

---

## Group Decision Methods

### Consensus Building

**Goal**: Everyone can live with the decision

**Process**:
1. Present top ideas
2. Discuss concerns for each
3. Modify ideas based on concerns
4. Test for consensus: "Can everyone support this?"
5. If no, address remaining concerns
6. Repeat until consensus

**Levels of consensus**:
- **Full**: Everyone fully supports
- **Adequate**: Everyone can live with it
- **Weak**: Some have reservations but will support

**Not consensus**: Forcing agreement, compromise, voting

**Time**: 20-30 minutes

**Best for**: Teams needing buy-in, important decisions

---

### Fist to Five

**Quick consensus check**:
- Show fingers (0-5)
- 0 = strong objection
- 1-2 = concerns
- 3 = neutral
- 4-5 = support

**Process**:
1. Present idea
2. Everyone shows fingers
3. If any 0-2, discuss concerns
4. Modify idea
5. Revote
6. Need mostly 3+ to proceed

**Time**: 5 minutes per idea

---

### Multi-Voting

**Narrow many options**:

**Process**:
1. Each person gets N votes (usually 1/3 of options)
2. Place votes (can put multiple on one idea)
3. Eliminate low-vote ideas
4. Repeat until down to 3-5
5. Deep discussion on remaining

**Time**: 10-15 minutes

---

### Decision Matrix

**Structured team evaluation**:

1. List ideas (rows)
2. List criteria (columns)
3. Team scores each idea on each criterion
4. Calculate totals
5. Discuss results
6. Make decision

Can weight criteria like weighted scoring

**Time**: 20-30 minutes

**Best for**: Complex decisions, need objectivity

---

### Delphi Method

**Anonymous expert consensus**:

**Process**:
1. Experts evaluate independently
2. Facilitator compiles anonymous feedback
3. Share compiled results
4. Experts reconsider their positions
5. Repeat 2-3 rounds
6. Converge on consensus

**Time**: Days to weeks (iterative)

**Best for**: Strategic decisions, avoiding groupthink

---

## Choosing an Evaluation Method

### Quick Reference

| Situation | Best Method |
|-----------|-------------|
| Time-constrained | Gut Check, Dot Voting, Three Stars |
| Need objectivity | Weighted Scoring, Feasibility Analysis |
| Many ideas to narrow | Multi-Voting, MoSCoW, Impact/Effort |
| Complex decision | Weighted Scoring, Risk Assessment |
| Group alignment needed | Consensus Building, Fist to Five |
| Resource planning | Impact/Effort Matrix, Feasibility |
| Risk assessment needed | Risk Matrix, Feasibility Analysis |
| Strategic planning | Weighted Scoring, Now/Next/Later |
| Product prioritization | Value vs Complexity, MoSCoW |

### Combining Methods

**Effective sequences**:

**Two-stage filter**:
1. Gut Check (narrow 50 → 15)
2. Impact/Effort Matrix (select top 5)

**Comprehensive analysis**:
1. Feasibility Analysis (identify viable)
2. Weighted Scoring (compare viable options)
3. Risk Assessment (understand trade-offs)
4. Group Consensus (make decision)

**Quick team decision**:
1. Dot Voting (initial preference)
2. Discuss top 5
3. Fist to Five (check consensus)

---

## Common Pitfalls

### Evaluation Traps to Avoid

**Premature convergence**:
- Stopping at first "good enough" idea
- Not exploring fully
- Solution: Set quantity targets before evaluating

**Analysis paralysis**:
- Over-analyzing every option
- Perfect being enemy of good
- Solution: Time-box evaluation, use simpler methods

**Groupthink**:
- Following loudest voice
- Not expressing concerns
- Solution: Anonymous voting, structured methods

**Pet project bias**:
- Creator defending their idea
- Not objective about own ideas
- Solution: Remove names from ideas, rotate evaluators

**Recency bias**:
- Favoring ideas generated last
- Forgetting earlier ideas
- Solution: Review all ideas before evaluating

**Scope creep during eval**:
- Modifying ideas while evaluating
- Mixing generation and evaluation
- Solution: Flag ideas for modification, evaluate as-is

---

## Best Practices

1. **Separate diverge and converge**: Never mix generation and evaluation
2. **Use multiple methods**: Different lenses reveal different insights
3. **Make criteria explicit**: Clear standards prevent arguments
4. **Document reasoning**: Future you will thank you
5. **Time-box everything**: Decisions don't improve infinitely with time
6. **Revisit parking lot**: Good ideas not chosen now might be perfect later
7. **Be transparent**: Show your evaluation process
8. **Trust the process**: Structured beats gut feelings
9. **Iterate if needed**: Can always re-evaluate with new information
10. **End with action**: Evaluation must lead to decisions and next steps

---

**Remember**: The goal of evaluation is not perfection, but progress. Choose a method, apply it consistently, make a decision, and move forward.
