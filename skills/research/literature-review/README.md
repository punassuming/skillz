# Scientific Literature Review Skill

A comprehensive skill for conducting systematic, evidence-based literature reviews that integrates multi-source searches, iterative analysis, and synthesis into well-structured, citable reports.

## Overview

This skill transforms the literature review process from a time-consuming, manual task into a systematic, reproducible, and efficient research methodology. Whether you're writing a research paper, grant proposal, dissertation, or conducting a systematic review, this skill provides proven strategies, tools, and workflows.

## What This Skill Does

### Core Capabilities

- **Multi-source search**: Integrate searches across PubMed, arXiv, Web of Science, Scopus, IEEE Xplore, ACM Digital Library, and web searches
- **Iterative refinement**: Systematically refine searches through concept extraction, citation mining, and gap identification
- **Content analysis**: Extract and organize bibliographic information, methodology, findings, and quality assessments
- **Thematic synthesis**: Organize findings by theme, research question, methodology, or chronological development
- **Quality assessment**: Evaluate research quality using established tools (GRADE, ROBINS-I, CASP)
- **Bias detection**: Identify publication bias, selection bias, and methodological limitations
- **Citation management**: Format citations in APA, Chicago, IEEE, Nature, Science, and other styles
- **Report generation**: Create comprehensive, well-structured literature review reports
- **Gap identification**: Identify research gaps, contradictions, and future research directions

### Review Types Supported

1. **Narrative Literature Reviews**: Comprehensive overviews of research topics
2. **Systematic Literature Reviews**: Exhaustive, methodology-driven reviews following PRISMA guidelines
3. **Scoping Reviews**: Landscape mapping with flexible inclusion criteria
4. **Meta-Analyses**: Quantitative synthesis of comparable studies

## When to Use This Skill

Use this skill when you need to:

### Academic Writing
- Write literature review chapters for dissertations or theses
- Develop comprehensive background sections for research papers
- Create introduction sections that synthesize prior work
- Support manuscript submissions with evidence synthesis

### Research Planning
- Identify gaps before starting research projects
- Understand the current state of knowledge in a domain
- Track methodological developments and trends
- Evaluate different research approaches

### Grant Proposals
- Write compelling, evidence-based background sections
- Demonstrate comprehensive knowledge of field
- Show gap in current knowledge
- Justify research approach and innovation

### Policy and Practice
- Support evidence-based decision-making
- Synthesize research for policy documents
- Create clinical practice guidelines
- Develop technology assessments

### Academic Evaluation
- Prepare for comprehensive exams (PhD qualifiers)
- Write literature review papers
- Create research overviews for promotion/tenure
- Document expertise in research area

## Quick Start Example

### Scenario: Systematic Review of Deep Learning in Medical Imaging

**Step 1: Define Research Question**
```
Research Question: What is the effectiveness and safety of deep learning models
compared to traditional machine learning and human experts for diagnostic accuracy
in medical imaging?

PICO Framework:
- Population: Patients undergoing medical imaging (any modality)
- Intervention: Deep learning-based diagnostic systems
- Comparison: Traditional ML, human experts, standard of care
- Outcome: Diagnostic accuracy, sensitivity, specificity, clinical outcomes
```

**Step 2: Plan Search Strategy**
```
Selected Databases:
- PubMed (biomedical literature)
- arXiv (ML methodology preprints)
- IEEE Xplore (engineering approaches)
- Web of Science (multidisciplinary)

Primary Search Query:
"deep learning" AND ("medical imaging" OR "radiology" OR "diagnosis")
AND ("accuracy" OR "performance" OR "sensitivity" OR "specificity")

Time frame: 2015-2025 (deep learning era)
Language: English
Study types: Empirical research (exclude opinion/editorial)
```

**Step 3: Execute and Track Initial Search**
```
Search Results:
- PubMed: 1,247 papers
- IEEE Xplore: 893 papers
- arXiv: 2,156 papers
- Web of Science: 3,421 papers
Total (after deduplication): 4,789 papers

First screening (titles): Remove obviously irrelevant
After title screening: 1,248 papers (26% pass rate)

Abstract screening: Apply inclusion criteria
After abstract screening: 387 papers (8% of original)
```

**Step 4: Iterative Refinement**
```
Analysis of initial 387 papers:
- Common methodologies identified:
  * Convolutional neural networks (245 papers, 63%)
  * Attention mechanisms (87 papers, 22%)
  * Vision Transformers (23 papers, 6%)

- Underrepresented areas:
  * Pediatric imaging (34 papers)
  * Rare diseases (12 papers)
  * Low-income country settings (8 papers)

New targeted searches:
1. "attention mechanisms" + "medical imaging"
   Result: 45 new papers (23 relevant)

2. "pediatric" + "deep learning" + "diagnosis"
   Result: 78 papers (12 new relevant papers)

3. "Vision Transformer" + "radiology"
   Result: 34 papers (8 new relevant papers)

Convergence check: New searches finding 20-30% new papers
→ Continue iterating
```

**Step 5: Full-Text Review and Data Extraction**
```
After iterative searches: 423 papers for full-text review
Obtained: 401 papers (95%)
Unable to obtain: 22 papers

After quality assessment and detailed inclusion/exclusion:
Final included papers: 178 papers

Quality distribution:
- High quality (GRADE: A): 34 papers (19%)
- Good quality (GRADE: B): 78 papers (44%)
- Fair quality (GRADE: C): 56 papers (31%)
- Poor quality (GRADE: D): 10 papers (6%)
```

**Step 6: Thematic Organization**
```
Main themes identified:

1. CANCER DIAGNOSIS (89 papers)
   - Breast cancer: 34 papers
     * Mammography (18)
     * Ultrasound (8)
     * MRI (8)
   - Lung cancer: 32 papers
   - Colorectal cancer: 15 papers
   - Other: 8 papers

2. TREATMENT PLANNING (45 papers)
   - Radiotherapy: 28 papers
   - Surgical guidance: 12 papers
   - Monitoring: 5 papers

3. RISK STRATIFICATION (32 papers)
   - Prognostic models: 20 papers
   - Biomarker prediction: 12 papers

4. EMERGING APPLICATIONS (12 papers)
   - Rare diseases
   - Low-resource settings
```

**Step 7: Synthesis and Findings**
```
Key findings:
✓ Deep learning shows superior performance vs. traditional ML
  (87 papers show improvement, effect size: moderate to large)

✓ Comparable to human experts in specific tasks
  (32 papers; 12 show superiority, 15 show equivalence, 5 show inferiority)

✓ Generalization challenges
  (45 papers report overfitting/poor generalization to new data)

? Safety and regulatory concerns
  (Only 23 papers address regulatory/safety aspects)

⚠ Publication bias detected
  - Positive results more common (87% show improvement)
  - Negative/null results underrepresented
  - High-impact journals biased toward novel methods
```

**Step 8: Identify Gaps**
```
Major research gaps:

1. POPULATION GAPS
   Gap: Limited research on pediatric patients
   Current: 34 papers (8% of literature)
   Needed: More diverse age groups

2. METHODOLOGY GAPS
   Gap: No direct comparison of DL vs. expert radiologists
   Current: Separate studies for each
   Recommendation: Prospective comparative studies

3. GENERALIZATION GAPS
   Gap: Limited evidence on model transfer to new institutions
   Current: Single-center studies dominant
   Recommendation: Multi-center validation studies

4. APPLICATION GAPS
   Gap: Limited real-world implementation studies
   Current: Lab/pilot studies dominant
   Recommendation: Implementation science approaches

5. EQUITY GAPS
   Gap: Underrepresentation of low-income settings
   Current: 8 papers on non-US, non-Europe settings
   Recommendation: Targeted research in diverse settings
```

**Step 9: Write Comprehensive Report**
```
Report sections:
1. Executive Summary (1 page)
   - 178 relevant papers synthesized
   - Deep learning superior to traditional ML
   - Significant generalization challenges
   - Major gaps in pediatric and low-resource settings

2. Introduction (2 pages)
   - Historical context
   - Clinical motivation
   - Research question and objectives

3. Methods (1.5 pages)
   - Search strategy documented
   - Inclusion/exclusion criteria
   - Quality assessment approach

4. Results (4 pages)
   - Selection flowchart
   - Paper characteristics
   - Quality assessment summary
   - Bias assessment

5. Thematic Analysis (12 pages)
   - Cancer diagnosis (3 pages)
   - Treatment planning (2 pages)
   - Risk stratification (2 pages)
   - Emerging applications (2 pages)
   - Methodological trends (3 pages)

6. Synthesis and Discussion (4 pages)
   - Integration of findings
   - Quality and bias assessment
   - Implications for practice
   - Implications for research

7. Research Gaps and Future Directions (2 pages)
   - Identified gaps
   - Priority research needs
   - Implementation challenges

8. Conclusions (1 page)
   - Summary of key findings
   - Clinical implications
   - Research implications

Total: ~30 pages with comprehensive citations
```

## Key Workflow Steps

### 1. Planning Phase
- Define clear research question (PICO format)
- Establish inclusion/exclusion criteria
- Select appropriate databases
- Develop search strategy
- Create documentation system

### 2. Initial Search Phase
- Execute searches across databases
- Track all search parameters
- Initial title/abstract screening
- Document pass rates

### 3. Iterative Refinement Phase
- Concept extraction from initial results
- Citation mining (reference lists + forward citation tracking)
- Author tracking (identify key researchers)
- Targeted searches for identified gaps
- Monitor for saturation (diminishing returns)

### 4. Full-Text Phase
- Obtain full texts
- Detailed inclusion/exclusion assessment
- Quality assessment using validated tools
- Structured data extraction

### 5. Analysis Phase
- Thematic organization
- Quality assessment and bias detection
- Evidence synthesis
- Gap identification
- Conflict identification

### 6. Writing Phase
- Outline structure
- Write sections with citations
- Integrate findings across themes
- Discuss gaps and implications
- Final quality review

### 7. Output Phase
- Format for target audience
- Generate citations (BibTeX, RIS, etc.)
- Verify all references
- Final formatting and review

## Tools Recommended by Reviewtype

### For All Literature Reviews

**Essential:**
- Reference manager: Zotero (free, open-source)
- Spreadsheet/database: Excel, Google Sheets, or Airtable
- Writing tool: Word, Google Docs, or Markdown + LaTeX

**Highly Recommended:**
- Citation formatter: CrossRef or DOI lookup
- Note-taking: OneNote, Notion, or Obsidian

### For Systematic Reviews

**Required:**
- PRISMA checklist for compliance
- Systematic review platform: Covidence or DistillerSR
- Quality assessment tools: GRADE, ROBINS-I, CASP

**Recommended:**
- Statistical software: R, Python, or STATA (for meta-analysis)
- Network visualization: VosViewer (for citation networks)
- Forest plot software: RevMan (for meta-analysis)

### For Narrative Reviews

**Recommended:**
- Concept mapping: CmapTools or MindMeister
- Visualization: Tableau or ggplot2
- Markdown editor: VS Code with Markdown extension

## Integration with Your Research Workflow

This skill integrates with:

### **scientific-writing** skill
Use together for:
- Writing literature review sections of manuscripts
- Formatting citations correctly
- Organizing section content
- Revising and improving prose

### **eln** (Electronic Lab Notebook) skill
Use together for:
- Documenting literature review process
- Recording search decisions
- Tracking paper annotations
- Storing extracted data
- Creating research timeline

### **planning** skill
Use together for:
- Setting literature review milestones
- Tracking progress toward completion
- Managing team assignments (for collaborative reviews)
- Scheduling database searches

### **phd-qualifier** skill
Use together for:
- Preparing for comprehensive exams
- Writing exam literature reviews
- Demonstrating comprehensive knowledge
- Creating study guides

## Output Examples

### Example 1: Literature Review Section for Research Paper

```markdown
## Background

The application of machine learning to [domain] has grown substantially
over the past decade. We conducted a systematic review of [X] papers
published between 2015-2025 to synthesize current knowledge and identify
research gaps.

### Current State of Knowledge

[Thematic summary of 1-2 sentences for each major finding]

### Methodological Approaches

[Summary of common approaches, with citations to exemplary papers]

### Open Questions and Limitations

[Discussion of conflicting findings, limitations, and gaps]
```

### Example 2: Standalone Literature Review Report

Structure: 20-40 pages with:
- Comprehensive searchable reference list
- Thematic sections with detailed discussion
- Evidence synthesis tables
- Quality and bias assessment
- Gap identification with recommendations

### Example 3: Grant Proposal Background

```
Project Background

[1-2 paragraph overview of field]

Current State of Knowledge

[Discussion of relevant research, with strategic citations to
show comprehensive knowledge]

Research Gap

[Clear articulation of what is NOT known, based on systematic review]

Research Innovation

[How proposed work addresses identified gap]
```

## Best Practices from This Skill

1. **Document everything**: Every search, decision, and finding recorded
2. **Iterate systematically**: Use initial results to refine strategy
3. **Quality over quantity**: One high-quality paper worth more than many poor-quality ones
4. **Synthesize, don't summarize**: Integrate findings, don't just list papers
5. **Address contradictions**: Acknowledge and explain conflicting findings
6. **Identify gaps**: Translate review into research agenda
7. **Maintain reproducibility**: Others should be able to replicate your search strategy
8. **Cross-verify**: Important findings should appear in multiple papers/databases
9. **Time-bound appropriately**: Comprehensive reviews take time; plan accordingly
10. **Use teams where possible**: Multiple reviewers improve quality and reduce bias

## Common Challenges and Solutions

### Challenge 1: Too Many Results
**Problem**: Broad search returns 10,000+ papers
**Solutions:**
- Narrow inclusion criteria
- Add specificity to search terms
- Use database filters (date, study type, etc.)
- Consider focused review instead of comprehensive

### Challenge 2: Insufficient Results
**Problem**: Narrow search returns <50 papers
**Solutions:**
- Broaden search terms and synonyms
- Include related concepts
- Search for grey literature
- Consider scoping review instead of systematic

### Challenge 3: Contradictory Findings
**Problem**: Papers reach opposite conclusions
**Solutions:**
- Compare methodologies (differences may explain contradictions)
- Assess quality (higher-quality studies may be more reliable)
- Look for study moderators (different populations, contexts)
- Note as area of uncertainty

### Challenge 4: Biased Literature
**Problem**: Predominantly positive results, few null/negative findings
**Solutions:**
- Search for negative studies explicitly
- Check grey literature (conferences, theses)
- Use funnel plots to detect bias
- Note publication bias in discussion
- Weight high-quality null findings appropriately

### Challenge 5: Limited Full-Text Access
**Problem**: Many papers behind paywalls
**Solutions:**
- Use institutional library access
- Use legal repositories (PubMed Central, arXiv, institutional repos)
- Contact authors directly for reprints
- Use Unpaywall to find legal OA versions
- Note limitation if significant access barriers exist

## Getting Started

### For Your First Literature Review:

1. **Choose review type**: Narrative, systematic, or scoping?
2. **Define your question**: Use PICO/PEO framework
3. **Select databases**: 2-3 primary, 1-2 supplementary
4. **Set up tracking**: Spreadsheet for papers and decisions
5. **Start searching**: Execute searches with full documentation
6. **Screen iteratively**: Title → Abstract → Full text
7. **Synthesize thematically**: Organize by theme, not by paper
8. **Write sections**: Guided by SKILL.md structure
9. **Verify citations**: All references complete and accurate
10. **Quality review**: Ensure logical flow and balanced perspective

### Time Expectations

- **Narrative review (focused)**: 4-8 weeks
- **Narrative review (comprehensive)**: 8-16 weeks
- **Systematic review (small scope)**: 3-6 months
- **Systematic review (large scope)**: 6-12+ months
- **Meta-analysis**: 6-18 months

These estimates assume 50-100 papers for narrative review, 100-300+ for systematic reviews.

## Conclusion

This skill provides a systematic, reproducible approach to literature reviews that:
- ✓ Saves time through efficient searching and organization
- ✓ Improves quality through structured analysis and synthesis
- ✓ Enhances credibility through transparent, documented methodology
- ✓ Creates comprehensive, citable reports with proper attribution
- ✓ Identifies actionable research gaps and future directions

Whether you're writing a paper, preparing for exams, planning research, or supporting policy decisions, this skill provides the methodology and guidance for conducting literature reviews that advance knowledge in your field.

---

**For comprehensive details, see SKILL.md. For quick reference, see QUICK_REFERENCE.md.**
